#!.venv/bin/python3

import cv2
from tqdm import tqdm
import os
from argparse import ArgumentParser
from transformers import AutoImageProcessor, DetrForObjectDetection
import torch
from torchvision.utils import draw_bounding_boxes
import subprocess

parser = ArgumentParser()
parser.add_argument("inputvid", type=str, help="input video file path to scan")
parser.add_argument("outputvid", type=str, nargs="?", help="output video file path")
parser.add_argument("-frames", type=int, help="max number of frames to scan")
args = parser.parse_args()

image_processor = AutoImageProcessor.from_pretrained("facebook/detr-resnet-50")
model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-50")

video = args.inputvid
vidreader = cv2.VideoCapture(video)

fps = vidreader.get(cv2.CAP_PROP_FPS)
total_frames = int(vidreader.get(cv2.CAP_PROP_FRAME_COUNT))
if args.frames:
    total_frames = min(total_frames, args.frames)
shape = (int(vidreader.get(cv2.CAP_PROP_FRAME_WIDTH)), int(vidreader.get(cv2.CAP_PROP_FRAME_HEIGHT)))
intermediate_file = "__inter__.mp4"

vidwriter = cv2.VideoWriter(intermediate_file, cv2.VideoWriter_fourcc(*"mp4v"), fps, shape)

# For every frame in the input video, load it, draw detection boxes from detr and save images to new video
for i in tqdm(range(total_frames), desc="Scanning video for objects and writing to new video"):
    # load frame from input and process it for the detr
    ret, frame = vidreader.read()
    frame = torch.from_numpy(frame.transpose(2, 0, 1))
    inputs = image_processor(images=frame, return_tensors="pt")

    # scan processed images for objects
    outputs = model(**inputs)

    # process model outputs
    target_sizes = torch.tensor([shape[::-1]])
    results = image_processor.post_process_object_detection(outputs, threshold=0.9, target_sizes=target_sizes)[0]

    frame = (255.0 * (frame - frame.min()) / (frame.max() - frame.min())).to(torch.uint8)
    frame = frame[:3, ...]
    pred_boxes = results["boxes"].long()
    labels = [f"{model.config.id2label[label.item()]}: {score} " for label, score in zip(results["labels"], results["scores"])]
    output_image = draw_bounding_boxes(frame, pred_boxes, labels, colors="red")

    # write the decoded frame to the new video
    vidwriter.write(output_image.cpu().numpy().transpose(1, 2, 0))
vidwriter.release()

if args.outputvid:
    output_path = args.outputvid
else:
    output_path = "trackedmedia.mp4"
# delete targed video if it exists, don't want any errors
if os.path.exists(output_path):
    os.remove(output_path)
# the media is corrupt in curtain file editors for whatever reason, running it through ffmpeg fixes this
subprocess.run(["ffmpeg", "-i", intermediate_file, output_path])
os.remove("__inter__.mp4")